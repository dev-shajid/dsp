
### **CSE_223_1.pdf: Signals, Systems, and Signal Processing**

#### **Introduction to Signals**
- A **signal** is defined as any physical quantity that varies with time, space, or any other independent variable.
- Mathematically, a signal is a function of one or more independent variables:
  - Examples include sound waves, vibrations of a spring, tsunami waves, surface ripples on water, seismic waves, and electromagnetic waves.
  - An image is an example of a signal with two independent variables.

- **Signal Generation** is associated with a system responding to a stimulus or force. For example, in speech, the system includes the vocal cords and the vocal tract.

#### **Systems and Signal Processing**
- A **system** is a device or software that performs an operation on a signal. 
  - For instance, a filter reducing noise is an example of a system.
  
- **Signal processing** is the operation performed by a system on a signal, which is characterized by the type of operation the system performs. 
  - For example, a filter eliminates noise.

- Signal processing can be done using:
  - **Analog signal processing systems**.
  - **Digital signal processing systems**.

- Most signals encountered in science and engineering are **analog** in nature. Analog signals are functions of a continuous variable (time or space) and take on values in a continuous range. These can be processed directly by analog systems.

- **Digital signal processing systems** perform processing digitally and may use a large programmable computer, a small microprocessor, or a hardwired digital processor.

#### **Advantages of Digital over Analog Signal Processing**
- **Flexibility**: Digital processing allows easy reconfiguration by changing the program, while analog requires hardware redesign.
- **Accuracy**: Digital systems provide better control of accuracy requirements, while analog components have tolerances.
- **Storage and Transportability**: Digital signals can be stored and processed offline, which is not possible with analog signals.
- **Sophisticated Algorithms**: Digital systems allow the implementation of more sophisticated signal processing algorithms.

#### **Classification of Signals**
- **Multichannel Signals**: Signals generated by multiple sources or sensors (e.g., ground acceleration due to an earthquake).
- **Multidimensional Signals**:
  - A signal that is a function of a single independent variable is called a **one-dimensional signal**.
  - A signal is called an **M-dimensional signal** if its value is a function of $ M $ independent variables.
  - A black-and-white TV picture can be represented as $ I(x, y, t) $, a three-dimensional signal.
  - A color TV picture is a three-channel, three-dimensional signal with intensity functions $ I_r(x, y, t) $, $ I_g(x, y, t) $, and $ I_b(x, y, t) $.

- **Continuous-Time Signals**: Defined for every value of time and take on values in a continuous interval.
- **Discrete-Time Signals**: Defined only at specific values of time, which are usually equidistant. They can arise by sampling an analog signal or by accumulating a variable over time.

- **Continuous-Valued Signals**: Can take on all possible values in a finite or infinite range.
- **Discrete-Valued Signals**: Can take on values from a finite set of possible values.

- An **analog signal** is a continuous-time, continuous-valued signal.
- A **digital signal** is a discrete-time signal having a set of discrete values.

- **Deterministic Signals**: Can be uniquely described by an explicit mathematical expression, a table of data, or a well-defined rule. All past, present, and future values are known precisely without any uncertainty.

- **Random Signals**: Cannot be accurately described by explicit mathematical formulas and evolve unpredictably.

#### **Concept of Frequency in Continuous-Time and Discrete-Time Signals**
- The nature of time (continuous or discrete) affects the nature of frequency.
  
- **Continuous-Time Sinusoidal Signals**:
  - A simple harmonic oscillation can be described as:
    $$
    S(t) = A \sin(\omega t + \theta)
    $$
  - For every fixed frequency $ F $, $ x_a(t) $ is periodic.
  - Distinct frequencies result in distinct signals.
  - Increasing the frequency $ F $ increases the rate of oscillation.
  - Mathematically, negative frequencies are introduced for convenience.

- **Discrete-Time Sinusoidal Signals**:
  - Expressed as:
    $$
    x(n) = A \cos(\omega n + \theta) \quad \text{or} \quad x(n) = A \cos(2 \pi f n + \theta)
    $$
    where $ n $ is the sample number, $ A $ is the amplitude, $ \omega $ is the frequency in radians per sample, and $ \theta $ is the phase in radians.
  - A discrete-time sinusoid is periodic only if its frequency $ f $ is a rational number.
  - Discrete-time sinusoids whose frequencies are separated by an integer multiple of $ 2\pi $ are identical.
  - The highest rate of oscillation is attained when $ \omega = \pi $ or equivalently, $f = \frac{1}{2}$.

#### **Aliasing**
- The sinusoids having the frequency $|\omega| > \pi$ are the alias of the corresponding sinusoids with frequestion $|\omega|<\pi$
- **Aliasing** occurs because periodic sampling of a continuous-time signal maps an infinite range of frequencies into a finite range for the discrete-time signal.
  - Frequencies $ F = F_0 + k F_s $, where $ k $ is an integer, are indistinguishable from $ F_0 $ after sampling and are aliases of $ F_0 $.
  - For example, with a sampling rate $ F_s = 40 $ Hz, a 50 Hz signal is an alias of a 10 Hz signal.

#### **Sampling of Analog Signals**
- **Sampling** is the process of selecting values of an analog signal at discrete-time instants.
- The relationship between continuous and discrete time variables is given by:
  $$
  t = n T
  $$
  where $ T $ is the sampling period.
  
- The reciprocal of $ T $ is the **sampling rate** $ F_s $ or **sampling frequency**:
  $$
  F_s = \frac{1}{T}
  $$
  
- The relationship between analog and digital frequencies is given by:
  $$
  f = \frac{F}{F_s}
  $$
  The highest frequency in a discrete-time signal is $ f = \frac{1}{2} $.

#### **The Sampling Theorem**
- **Shannon's sampling theorem** states that a continuous-time signal with no frequency components higher than $ F_{\text{max}} $ can be completely determined by samples taken at a rate $ F_s \geq 2 F_{\text{max}} $.
  - The minimum sampling rate $ F_s = 2 F_{\text{max}} $ is called the **Nyquist rate**.
  - To avoid aliasing, the sampling rate must be selected such that $ F_s > 2 F_{\text{max}} $.

#### **Quantization of Continuous-Amplitude Signals**
- **Quantization** is the process of converting a discrete-time continuous-amplitude signal into a digital signal by expressing each sample as a finite number of digits.
  - The error introduced in this process is called **quantization error** or **quantization noise**, and is given by:
    $$
    e_q(n) = x_q(n) - x(n)
    $$
  - Quantization is an irreversible process because samples within a certain distance of a quantization level are assigned the same value.

#### **Digital-to-Analog Conversion**
- This topic is mentioned but not detailed in the document.

---


# **CSE_223_2.pdf: ntroduction to Discrete-Time Signals**

### **What is a Discrete-Time Signal?**
- A **discrete-time signal** is a sequence of values, denoted as **x(n)**, where **n** represents the time index, typically an integer.
- Unlike continuous-time signals, discrete-time signals are only defined at integer values of **n** and are not defined for non-integer values of **n**.
  
### **Graphical Representation:**
- Discrete-time signals are displayed as a series of **discrete points** on a graph. The time origin (**n=0**) is typically marked with a symbol (↑).

### **Sampling:**
- Discrete-time signals are obtained by sampling an **analog signal** (xa(t)), where **x(n)** is defined as **xa(nT)**, with **T** being the sampling period.

---

# **Elementary Discrete-Time Signals**

### **1. Unit Sample Sequence (Unit Impulse):**
- A signal that is **1** at **$n=0$** and **0** everywhere else.

### **2. Unit Step Signal:**
- A signal that is **0** for **n<0** and **1** for **n≥0**.

### **3. Unit Ramp Signal:**
- A signal whose value increases **linearly** with time for **$n≥0$**.

### **4. Exponential Signal:**
- **Real Exponential:** When the parameter **a** is real, the signal is a simple exponential.
- **Complex Exponential:** If **a** is complex (i.e., **a = re^(jθ)**), the signal is a complex exponential, represented as:
  - **$r^n * e^(jθn)$** or equivalently **$r^n(cos(θn) + jsin(θn))$**.
- The **magnitude** of the complex exponential is **$A(n) = r^n$**, and the **phase** is **$∅(n) = θn$**.

---

# **Classification of Discrete-Time Signals**

### **1. Energy Signals and Power Signals:**

- **Energy:** The capacity of a signal to create a change.
$$
E=\sum_{n=-\infty}^\infty |x[n]|^2
$$
- **Power:** The rate at which energy is used or transmitted.
$$
P= \lim_{N\to\infty}\frac{1}{(2N+1)} \sum_{n=-N}^N |x[n]|^2
$$

#### **Energy Signal:**
- A signal **x(n)** is an **energy signal** if its **total energy** **E** (calculated by summing the squared magnitudes of the signal) is finite (**0 < E < ∞**).

#### **Power Signal:**
- The **average power** **P** of a discrete-time signal **x(n)** is calculated as the average of the sum of the squared magnitudes of the signal. If **P** is finite and non-zero, the signal is a **power signal**.

#### **Key Relationships:**
- If **E** is finite, **P = 0**.
- If **E** is infinite, **P** can be finite or infinite.
- A signal cannot be both an energy signal and a power signal; they are **mutually exclusive**.
- A signal is neither an energy nor a power signal if both energy and power are infinite.
- **Practical Signals:** Most practical signals are energy signals with finite duration and amplitude. Power signals require infinite duration, making them physically impossible to generate.
- Signals with **constant amplitude** over an infinite duration are **power signals**.

### **2. Periodic and Aperiodic Signals:**

#### **Periodic Signal:**
- A signal **$x(n)$** is periodic with **period N** if **$x(n + N) = x(n)$** for all **n**. The smallest such **N** is called the **fundamental period**.

#### **Aperiodic Signal:**
- A signal is **aperiodic** (or non-periodic) if no such **N** exists.

### **3. Symmetric (Even) and Antisymmetric (Odd) Signals:**

#### **Symmetric (Even) Signal:**
- A signal **x(n)** is **symmetric** (even) if **x(-n) = x(n)**.

#### **Antisymmetric (Odd) Signal:**
- A signal **x(n)** is **antisymmetric** (odd) if **x(-n) = -x(n)**.

- Any arbitrary signal can be expressed as the sum of an **even** and an **odd** signal:
  - **Even component:** **$(x(n) + x(-n)) / 2$**
  - **Odd component:** **$(x(n) - x(-n)) / 2$**

---

# **Simple Manipulations of Discrete-Time Signals**

### **1. Time Shifting:**
- Replacing **n** with **n - k** shifts the signal in time.
  - If **k** is positive, it is a **delay**.
  - If **k** is negative, it is an **advance**.

### **2. Time Reversal (Folding):**
- Replacing **n** with **-n** reflects the signal about the time origin (**$n = 0$**).

### **3. Time Scaling (Down-sampling):**
- Replacing **n** with **$μn$**, where **μ** is an integer, scales the time base.
  - For example, **$y(n) = x(2n)$** represents **down-sampling** the signal.

### **4. Amplitude Modifications:**

#### **Amplitude Scaling:**
- Multiplying the signal by a constant **A** scales the amplitude of every sample.

#### **Addition of Signals:**
- Adding two signals, **x1(n)** and **$x2(n)$**, results in a new signal **y(n) = x1(n) + x2(n)**.

#### **Multiplication of Signals:**
- The product of two signals is calculated sample-by-sample: **$y(n) = x1(n) * x2(n)$**.

---

# **Discrete-Time Systems**

### **Definition:**
- A **discrete-time system** is a device or algorithm that transforms a **discrete-time input signal** into a corresponding **output signal**.

### **Input-Output Relationship:**
- The system’s behavior can be described by the relationship between its **input** and **output** signals.

### **Block Diagram Representation:**
- Basic building blocks include:
  - **Adder:** Sums two or more signals.
  - **Constant Multiplier:** Multiplies a signal by a constant.
  - **Signal Multiplier:** Multiplies two signals.
  - **Unit Delay Element:** Delays the signal by one sample.
  - **Unit Advance Element:** Advances the signal by one sample.

---

# **Classification of Discrete-Time Systems**

### **1. Static vs. Dynamic Systems:**

#### **Static (Memoryless) System:**
- The output depends only on the current input, not on past or future inputs.

#### **Dynamic System:**
- The output depends on past or future inputs, implying the system has **memory**.

### **2. Time-Invariant vs. Time-Variant Systems:**

#### **Time-Invariant System:**
- The system’s behavior doesn’t change with time. Shifting the input by **k** samples results in the same shift in the output.

#### **Time-Variant System:**
- The system’s behavior changes with time.

### **3. Linear vs. Nonlinear Systems:**

#### **Linear System:**
- A system that satisfies the **superposition principle** (the output is the sum of the individual responses to each input signal).

#### **Nonlinear System:**
- A system that does not satisfy the superposition principle.

### **4. Causal vs. Noncausal Systems:**

#### **Causal System:**
- The output depends only on **present** and **past** inputs, not on future inputs.

#### **Noncausal System:**
- The output depends on **future** inputs.

### **5. Stable vs. Unstable Systems:**

#### **Stable (BIBO) System:**
- A system is stable if **bounded input** results in a **bounded output**.

#### **Unstable System:**
- If a bounded input leads to an **unbounded** output, the system is unstable.

---

# **Interconnection of Discrete-Time Systems**

- Systems can be interconnected to form larger systems using configurations such as **cascade** (series) and **parallel** arrangements.

---

# **Analysis of Linear Time-Invariant (LTI) Systems**

### **Techniques for Analysis:**
- Directly solve the input-output equations or decompose the input signal into elementary components and apply linearity to find the total output.

### **Impulse Response:**
- The **impulse response** of an LTI system is the response to an input **δ(n-k)** (the unit sample).

### **Convolution Sum:**
- The output **y(n)** of an LTI system is given by the **convolution sum** of the input signal **x(n)** and the system’s impulse response **h(n)**:
  - **$y(n) = \sum_{k=-\infty}^\infty x(k)h(n-k)$**

---

# **Correlation of Discrete-Time Signals**

### **Objective:**
- To measure the degree of similarity between two signals.

### **Applications:**
- Used in areas such as radar, sonar, digital communications, and geology.

### **Crosscorrelation and Autocorrelation:**
- Methods for measuring similarity between signals.

---

# **In Summary**

This document provides an essential overview of **discrete-time signals** and **systems**, covering:
- The definition and manipulation of discrete-time signals.
- The classification of signals by energy, power, periodicity, and symmetry.
- The properties of various systems, including **LTI systems**, and the analysis using techniques like **convolution** and **correlation**.

This provides a fundamental understanding for anyone beginning in the field of discrete-time signal processing and system analysis.

---

# Previous Year Question:
Here is the improved version of your summary with mathematical expressions formatted in LaTeX:

---

### **CSE_223_1.pdf: Signals, Systems, and Signal Processing**

#### **Q.1(a)** Define signal, system, and signal processing. What are the advantages of digital signal processing over analog signal processing?

- A **signal** can be defined as a function that conveys information about a phenomenon.
- A **system** is an entity that processes a signal to modify or extract useful information.
- **Signal processing** involves the analysis, modification, and synthesis of signals to achieve specific goals.
- **Advantages of digital signal processing over analog signal processing**:
  - Digital systems are more flexible and can be easily reprogrammed.
  - Digital systems offer better accuracy, repeatability, and stability compared to analog systems.
  - Digital signals can be stored easily and transmitted without loss of information.

---

#### **Q.1(b)** What are the characterizing properties of continuous-time and discrete-time sinusoidal signals? In the case of discrete-time sinusoidal signals, what happens for $ \omega = 0 $ or $ \omega = 2\pi $?

- **Continuous-time sinusoidal signals** are characterized by their amplitude, frequency, and phase, and are continuous functions of time.
- **Discrete-time sinusoidal signals** are also characterized by their amplitude, frequency, and phase, but they are defined only at discrete points in time.
- For a discrete-time sinusoidal signal, if $ \omega = 0 $, the signal becomes a constant value equal to the amplitude, it stops oscillating and becomes a DC signal (no change from sample to sample). If $ \omega = 2\pi $, the signal also becomes constant because it will complete an exact number of cycles within one sample interval, again, making the value constant. These signals are said to be aliases of DC.

---

#### **Q.1(c)** What is sampling frequency? With necessary figure explain how sampling converts an analog signal to a discrete-time continuous-valued signal.

- **Sampling frequency** ($ f_s $) is the number of samples taken per second when converting a continuous signal to a discrete one. The reciprocal of the sampling frequency is known as the sampling period $ T $.
- The process of **sampling** involves measuring the value of an analog signal at regular intervals, which effectively converts it into a sequence of discrete values. These values are then discrete-time continuous-valued signals.

---

#### **Q.1(d)** Tabulate the relations among the frequency variables of continuous-time and discrete-time signals.

Let $ f $ represent frequency in Hertz (cycles per second), $ F $ represent normalized frequency with respect to sampling frequency, and $ \Omega $ represent angular frequency in radians per second for a continuous signal, and $ \omega $ represents angular frequency of the discrete signal. Then the relations between continuous and discrete time frequencies are as follows:

- **Continuous-time angular frequency**: $ \Omega = 2 \pi f $
- **Normalized frequency**: $ F = \frac{f}{f_s} $, where $ f_s $ is the sampling frequency.
- **Discrete-time angular frequency**: $ \omega = \Omega T = 2\pi fT =  2 \pi \frac{f}{f_s} = 2 \pi F $, where $ T $ is the sampling period.

**Relations**: 
$$
\omega = \Omega T, \quad F = \frac{f}{f_s}, \quad \omega = 2\pi F
$$

---

#### **Q.2(a)** Consider the analog signal $ x(t) = 3 \cos(100\pi t) $.
- **i) Determine the minimum sampling rate required to avoid aliasing.**
  - The frequency of the analog signal is:
    $$
    f = \frac{100\pi}{2\pi} = 50 \, \text{Hz}.
    $$
  - According to the Nyquist-Shannon sampling theorem, the minimum sampling rate $ f_s $ should be twice the highest frequency component of the signal to avoid aliasing. Therefore, the minimum sampling rate is:
    $$
    f_s = 2 \times 50 = 100 \, \text{Hz}.
    $$
- **ii) Suppose that the signal is sampled at the rate $ f_s = 200 $ Hz. What is the discrete-time signal obtained after sampling?**
  - If $ f_s = 200 $ Hz, then the sampling period $ T = \frac{1}{200} $.
  - The discrete-time signal can be expressed as:
    $$
    x[n] = x(nT) = 3 \cos \left( 100\pi nT \right) = 3 \cos \left( \frac{100\pi n}{200} \right) = 3 \cos \left( \frac{\pi}{2} n \right).
    $$
- **iii) Repeat part (ii) for $ f_s = 75 $ Hz.**
  - If $ f_s = 75 $ Hz, then $ T = \frac{1}{75} $.
  - The discrete-time signal can be written as:
    $$
    x[n] = 3 \cos \left( 100\pi n \frac{1}{75} \right) = 3 \cos \left( \frac{4\pi}{3} n \right).
    $$
- **iv) What is the frequency $ f = \frac{f_s}{2} $ of a sinusoid that yields samples identical to those obtained in part (iii)?**
  - If the frequency is $ f_s/2 $, it will be equal to:
    $$
    \frac{75}{2} = 37.5 \, \text{Hz}.
    $$
  - The continuous-time signal is:
    $$
    x(t) = 3 \cos(2\pi 37.5 t) = 3 \cos(75 \pi t),
    $$
    and for $ f_s = 75 $ Hz, we get:
    $$
    x[n] = 3 \cos \left( \frac{75\pi n}{75} \right) = 3 \cos(\pi n).
    $$
  - The frequency $ f = 37.5 $ Hz gives a result similar to the result in part (iii).

---

#### **Q.2(b)** State Shannon's sampling theorem. What is Nyquist rate? Consider the analog signal $ x(t) = 5 \cos(2000\pi t) + 5 \cos(12000\pi t) $.
- **i) What is the Nyquist rate for this signal?**
  - The **Nyquist-Shannon sampling theorem** states that a continuous-time signal can be perfectly reconstructed from its samples if the sampling rate is at least twice the maximum frequency component of the signal.
  - The **Nyquist rate** is the minimum sampling rate required to avoid aliasing.
  - For the given signal, the frequencies are:
    $$
    f_1 = \frac{2000\pi}{2\pi} = 1000 \, \text{Hz}, \quad f_2 = \frac{12000\pi}{2\pi} = 6000 \, \text{Hz}.
    $$
    The highest frequency is $ 6000 \, \text{Hz} $.
    $$
    \text{Nyquist rate} = 2 \times 6000 = 12000 \, \text{Hz}.
    $$
- **ii) Assume now that we sample this signal using a sampling rate $ f_s = 5000 $ samples/s. What is the discrete-time signal obtained after sampling?**
  - The sampling frequency $ f_s = 5000 $ Hz, then the sampling period $ T = \frac{1}{5000} $ seconds.
  - The signal $ x(t) = 5 \cos(2000\pi t) + 5 \cos(12000\pi t) $ becomes:
    $$
    x[n] = 5 \cos\left( \frac{2000\pi n}{5000} \right) + 5 \cos\left( \frac{12000\pi n}{5000} \right) = 5 \cos\left( \frac{2\pi}{5} n \right) + 5 \cos\left( \frac{12\pi}{5}n \right).
    $$
    However, because $ \cos(\theta) = \cos(\theta + 2\pi k) $, where $ k $ is an integer, we can simplify:
    $$
    \cos\left( \frac{12\pi}{5}n \right) = \cos\left( \left( \frac{12\pi}{5} - 2\pi \right) n \right) = \cos\left( \frac{2\pi}{5}n \right).
    $$
    Thus, the discrete-time signal will be given as:
    $$
    x[n] = 10 \cos\left( \frac{2\pi}{5}n \right).
    $$

---

#### **Q.2(c)** The discrete-time signal $ x(n) = 6.35 \cos\left( \frac{\pi n}{16} \right) $ is quantized with a resolution (i) $ \Delta = 0.1 $ or (ii) $ \Delta = 0.02 $. How many bits are required in the A/D converter in each case?

- **Quantization** is the process of approximating the continuous range of signal values to a discrete set of values.
- **Resolution** $ \Delta $ refers to the smallest change in the analog value that can be represented by the digital output. The signal's amplitude varies between $ -6.35 $ and $ 6.35 $, so the total dynamic range of the signal is $ 12.7 $.
  - **(i) $ \Delta = 0.1 $**: The number of levels is:
    $$
    N = \frac{12.7}{0.1} = 127.
    $$
    To find the number of bits ($ n $) required to represent 127 levels, we calculate:
    $$
    2^n \geq 127.
    $$
    Here, $ 2^7 = 128 $, so we need 7 bits.
  - **(ii) $ \Delta = 0.02 $**: The number of levels is:
    $$
    N = \frac{12.7}{0.02} = 635.
    $$
    Since $ 2^9 = 512 $ and $ 2^{10} = 1024 $, we need 10 bits to represent 635 levels because $ 2^{10} > 635 $ and $ 2^9 < 635 $.

---

#### **Q.2(d)** Distinguish between Symmetric and Antisymmetric Signals. Show that any arbitrary signal can be expressed as the sum of two signal components, one of which is even and the other is odd.

- A **symmetric (or even) signal** is one where:
  $$
  x(n) = x(-n).
  $$
- An **antisymmetric (or odd) signal** is one where:
  $$
  x(n) = -x(-n).
  $$
- Any arbitrary signal $ x(n) $ can be represented as the sum of an even component $ x_e(n) $ and an odd component $ x_o(n) $, such that:
  $$
  x(n) = x_e(n) + x_o(n).
  $$
- The even and odd components can be found using the relations:
  $$
  x_e(n) = \frac{1}{2} \left[ x(n) + x(-n) \right],
  $$
  $$
  x_o(n) = \frac{1}{2} \left[ x(n) - x(-n) \right].
  $$

---

#### **Q.4(a)** What is the region of convergence (ROC) in Z-transform? What would be the ROC for causal, anticausal, and two-sided signals? Describe by plotting those for infinite duration discrete signals.

- The **Region of Convergence (ROC)** of a Z-transform is the set of values of $ z $ for which the Z-transform converges (the sum converges).
- For a **causal signal**, the ROC is outside a circle of radius $ r $ (i.e., $ |z| > r $) where $ r $ is the largest magnitude of a pole.
- For an **anticausal signal**, the ROC is inside a circle of radius $ r $ (i.e., $ |z| < r $) where $ r $ is the smallest magnitude of a pole.
- For a **two-sided signal**, the ROC is a ring (i.e., $ r_1 < |z| < r_2 $).

---
